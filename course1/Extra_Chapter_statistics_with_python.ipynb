{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Statistics with python\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content <a id='toc'></a>\n",
    "\n",
    "<br>\n",
    "\n",
    "1. **[SciPy.stats and statistics in python](#stats)**  \n",
    "    1.1 [manipulation of random distributions](#stats.1)  \n",
    "     1.1.1 [Drawing some random numbers : rvs](#stats.1.1)  \n",
    "     1.1.2 [Looking up the quantiles and probability density functions](#stats.1.2)  \n",
    "    1.2 [t-test](#stats.2)  \n",
    "    1.3 [statistical power calculations](#stats.3)  \n",
    "    1.4 [Multiple hypothesis testing](#stats.4)  \n",
    "    1.5 [Fisher's exact test and the Chi-square test](#stats.5)  \n",
    "    1.6 [1-way anova](#stats.6)  \n",
    "    <br>\n",
    "\n",
    "2. **[Correlation and linear regression](#reg)**  \n",
    "    2.1 [Correlation](#reg.1)  \n",
    "    2.2 [Regression](#reg.2)  \n",
    "    <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook aims to present how to perform classical statistical procedure as well as some amount of regression using various python libraries, such as **`scipy`**.\n",
    "\n",
    "It **does not aim to replace a course on statistics**, but rather focuses on the code aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels\n",
    "from IPython.display import Image\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: if you are missing some of the above modules, you should install them.\n",
    ">\n",
    ">    * Installation with **pip**: `pip install --user matplotlib seaborn scipy pandas numpy statsmodels` \n",
    ">    * Installation with **conda**: `conda install -c conda-forge matplotlib seaborn scipy pandas numpy statsmodels`\n",
    "\n",
    "<br>\n",
    "\n",
    "Making the plotted labels a bit bigger for presentation with a projector... you do **not need to run this cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "font = {\n",
    "    \"family\": \"DejaVu Sans\",\n",
    "    \"weight\": \"bold\",\n",
    "    \"size\"  : 20\n",
    "}\n",
    "mpl.rc(\"font\", **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 1. `scipy.stats` and statistics in python <a id='stats'></a>\n",
    "-----------------------------------------------------------\n",
    "\n",
    "**[SciPy](https://scipy.org)** is a comprehensive project for scientific python programming, regrouping a [library](https://docs.scipy.org/doc/scipy/reference/) and implementing various tools and algorithm for scientific computation.\n",
    "\n",
    "This section gives a primer on the **`scipy.stats`** library, which provides ways to interact with various random distribution functions, and implements numerous statistical tests.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## 1.1 manipulation of random distributions <a id='stats.1'></a>\n",
    "\n",
    "The **`scipy.stats`** module implements utilities for a large number of continuous and discrete distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "dist_continu = [d for d in dir(stats) if isinstance(getattr(stats, d), stats.rv_continuous)]\n",
    "dist_discrete = [d for d in dir(stats) if isinstance(getattr(stats, d), stats.rv_discrete)]\n",
    "print(\"Number of continuous distributions: %d\" % len(dist_continu))\n",
    "print(\"Number of discrete distributions:   %d\" % len(dist_discrete))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment with the normal distribution, or **`norm`** in `scipy.stats`\n",
    "\n",
    "A look at `help(stats.norm)` tells us that:\n",
    "* The **`loc`** argument (location) specifies the **mean** of the distribution.\n",
    "* The **`scale`** argument specifies the **standard deviation** of the distribution.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example:** generate a specific normal distribution with a mean of 10 and a stdev of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = stats.norm(loc=10, scale=2)\n",
    "\n",
    "# The mean and variance of a distribution can be retrieved using the .stats method:\n",
    "print(\"Type of N is:\", type(N))\n",
    "print(\"Mean and variance of distribution:\", N.stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(N.stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scipy distribution object (`N` in our example) can then be used to interact with the distribution in many ways, as illustrated below.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1.1.1. Drawing random numbers: `rvs` <a id='stats.1.1'></a>\n",
    "\n",
    "The **`rvs()`** method allows to draw a random number of values from a distribution.\n",
    "* The `size` argument can be an integer or a sequence of several integers, this defines the\n",
    "  dimensions of the returned arrays of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of 10 random numbers, returned as a 1-dimensional array.\n",
    "N.rvs(size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of 10 random numbers, returned as a 2-dimensional array (5 rows, 2 cols).\n",
    "N.rvs(size=(5, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw 5000 random numbers from the distribution and plot them.\n",
    "plt.hist(N.rvs(size=5000)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "**Warning:** as with any drawing of random variable on a computer, [one merely emulates randomness](https://en.wikipedia.org/wiki/Pseudorandom_number_generator).  \n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive aspect of using pseudo-random numbers is that one can make random operation reproducible by setting up **random seed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the random seed and draw 5 random numbers:\n",
    "np.random.seed(2023)   \n",
    "draw1 = N.rvs(size=5)\n",
    "\n",
    "# Set the random seed back to the same value as above -> 2021.\n",
    "np.random.seed(2023)\n",
    "draw2 = N.rvs(size=5)\n",
    "\n",
    "print(\"Are the random draws equal?\", all(draw1 == draw2))\n",
    "print(draw1)\n",
    "print(draw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.2 Looking-up quantiles and probability density functions <a id='stats.1.2'></a>\n",
    "\n",
    "* **`pdf()`: Probability Density Function** - the probability that a random number has a value equal\n",
    "  (or close to) the value passed to the function.\n",
    "* **`cdf()`: Cumulative Distribution Function** - the probability that a random number has a value lower or \n",
    "  equal to the value passed to the function.\n",
    "* **`ppf()`: Percent Point Function** (inverse of CDF) - gives the quantiles of the distribution.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example:** using the PDF to plot a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "X = np.arange(0, 20, 0.1)      # Generate a sequence ranging from 0 to 20 with increment of 0.1\n",
    "plt.plot(X, N.pdf(X))          # For each element of the sequence, get the associated PDF value.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Example:** using the CDF to estimate a probability, using PPF to compute quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf: Cumulative Distribution Function.\n",
    "print('What is the probability of drawing a number <= 15.0 ?', N.cdf(15.0))\n",
    "\n",
    "# ppf: gives the quantiles of the distribution.\n",
    "P = [0.025, 0.5, 0.975]\n",
    "Q = N.ppf(P)\n",
    "print('Quantiles:', P, '->', Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "For **discrete distribution** these rules change a bit: `pdf()` is replaced by `pmf()`.\n",
    "\n",
    "Let's see an example of **binomial distribution** with 10 draws and a 0.5 probability of success:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0,10)   # Generate a sequence of integer number from 0 to 9.\n",
    "plt.scatter(X, stats.binom.pmf(X, n=10, p=0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most distributions have a certain number of **parameters** which control their overall **shape, location or scale**.\n",
    "* The **normal distribution** e.g. has two parameters: its mean ($\\mu$) and its standard deviation ($\\sigma$), \n",
    "  which respectively control its location and scale. In `scipy`, these are set via the `loc` (location)\n",
    "  and `scale` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate 100 equally separated points between -5 and 5,\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "a = sns.lineplot(\n",
    "    x=x, y=stats.norm.pdf(x, loc=0 , scale=1),\n",
    "    ax=ax, label=\"mean=0, stdev=1\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=x, y=stats.norm.pdf(x, loc=-2, scale=1) ,\n",
    "    ax=ax, label=\"mean=-2, stdev=1\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=x, y=stats.norm.pdf(x, loc=1, scale=3) ,\n",
    "    ax=ax, label=\"mean=1, stdev=3\")\n",
    "\n",
    "a.set(xlabel=\"value\", ylabel=\"density\")\n",
    "a.set_title(\"normal law - probability density function\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## 1.2 t-test <a id='stats.2'></a>\n",
    "\n",
    "[**Student's t-test**](https://en.wikipedia.org/wiki/Student%27s_t-test) is used to determine if the means of two samples (drawn from 2 sub-populations for instance) are significantly different.\n",
    "\n",
    "It is a widely used test, with important but not overly complex assumptions:\n",
    " * Independence of data points.\n",
    " * The means of each sample should follow normal distributions.\n",
    " * *The two sample share the same variance* (there are different flavors of the t-test depending\n",
    "   on that assumption).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example:** weight of mice of different genotypes and subjected to different diets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_data = pd.read_csv(\"data/mice_data.csv\")\n",
    "sns.catplot(x=\"weight\", y=\"genotype\", data=mice_data, kind=\"violin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test has a number of assumptions, mostly the normality of means of each group.\n",
    "\n",
    "We can get an approximate idea of this with a pair of QQplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data = mice_data[\"weight\"][mice_data[\"genotype\"] == \"WT\"]\n",
    "KO_data = mice_data[\"weight\"][mice_data[\"genotype\"] == \"KO\"]\n",
    "\n",
    "fig,ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "stats.probplot(WT_data, dist=\"norm\", plot=ax[0], rvalue=True)\n",
    "ax[0].set_title(\"WT data\")\n",
    "stats.probplot(KO_data, dist=\"norm\", plot=ax[1], rvalue=True)\n",
    "ax[1].set_title(\"KO data\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the t-test itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: use equal_var=True if you have tested for variance equality.\n",
    "tstat, pval = stats.ttest_ind(KO_data, WT_data, equal_var=False)\n",
    "\n",
    "print(\"test statistic:\", tstat)\n",
    "print(\"p-value       :\", pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Micro-Exercise 1\n",
    "* There is another column in the `mice_data` data-set : `diet`, which can take the values `\"HFD\"` and `\"CHOW\"`.\n",
    "  Perform a t-test exactly as before, but splitting mice by their `diet` rather than their `genotype`.\n",
    "    \n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## 1.3 Statistical power calculations <a id='stats.3'></a>\n",
    "\n",
    "Statistical **power** is the probability that a test correctly rejects the Null Hypothesis (if the alternative Hypothesis is true).\n",
    "\n",
    "For some widely used tests, functions exist to let you automatically compute statistical power for a given effect size or sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "mean_difference = 1\n",
    "standard_dev = 1\n",
    "sample_size = 10\n",
    "\n",
    "effect_size = mean_difference/standard_dev\n",
    "\n",
    "P = TTestIndPower()\n",
    "print('power:', P.power(effect_size=effect_size, nobs1=sample_size, ratio=1, alpha=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating statistical power can help inform our experimental design**. \n",
    "\n",
    "For example, how many observation per sample do we need if we want to detect a difference in mean of 1 with significance level (type I error) 0.01 and statistical power 0.80:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size = 1\n",
    "sig_threshold = 0.01\n",
    "P = TTestIndPower()\n",
    "\n",
    "powers = []\n",
    "for sample_size in range(2, 50):\n",
    "    powers.append(P.power(effect_size=effect_size, nobs1=sample_size, ratio=1, alpha=sig_threshold))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "sns.lineplot(x=range(2, 50), y=powers, label=\"effect size=\" + str(effect_size), ax=ax)\n",
    "ax.axhline(0.8, color=\"r\", linestyle=\"-\")\n",
    "ax.set(xlabel=\"sample size\", ylabel=\"power\")\n",
    "\n",
    "\n",
    "# Or, directly:\n",
    "print(\"minimum sample size:\",\n",
    "      P.solve_power(\n",
    "          effect_size=effect_size,\n",
    "          nobs1=None,\n",
    "          ratio=1,\n",
    "          alpha=sig_threshold,\n",
    "          power=0.8\n",
    "      )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to compute power not only exists for t-test, but also for others such as Chi-square, Anova, F-test, Z-test.\n",
    "\n",
    "See the [documentation](https://www.statsmodels.org/dev/stats.html#power-and-sample-size-calculations) for a lists and details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## 1.4 Multiple hypothesis testing <a id='stats.4'></a>\n",
    "\n",
    "Recall the **definition of the p-value**: the probability of obtaining a test statistic at least as extreme as the one observed, **if the null hypothesis is true**\n",
    "\n",
    "Thus, *even* if the p-value is, let's say, 0.04, there is still a 4% chance of obtaining such an extreme result **purely by chance**.\n",
    "\n",
    "This is often acceptable if we only perform one test. However when **multiple tests** are performed, it was shown (by simulation), that even when there is no real effect some tests will turn out significant by chance.\n",
    "\n",
    "> This is the definition of the $\\alpha$ risk of type I error.\n",
    "\n",
    "Of course, this has important implication for science and the relevance of our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/xkcd882.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> source: [xkcd](http://xkcd.com) (note: there are many relevant xkcd strips for everything related to stats/programming courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([1, 2, 5, 10, 50, 100])\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.plot(P, 1 - 0.95 ** P)\n",
    "ax.set(xlabel=\"number of tests\", ylabel=\"probability of at least 1 test significant by chance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We need to change perspective.\n",
    "Instead of trying to limit the false positive probability for *each* test, we focus on:\n",
    "* The probability of obtaining **any** false positives (family-wise error rate, **FWER**).\n",
    "* The proportion of false positives among all findings (false discovery rate, **FDR**).\n",
    "\n",
    "> Controlling the FWER is often too stringent - limit type I errors, but get lots of type II errors. \n",
    "\n",
    "<br>\n",
    "\n",
    "### The Bonferroni method for controlling the FWER\n",
    "* Assume we are performing $N$ tests.\n",
    "* To control the FWER at (e.g.) 0.05, only call variables with p-values below $0.05/N$ significant.\n",
    "\n",
    "<br>\n",
    "\n",
    "### The Benjamini-Hochberg method for controlling the FDR\n",
    "\n",
    "- Assume we are performing $N$ tests.\n",
    "- Intuition: for each p-value threshold $\\alpha$, we can estimate the number of false discoveries by $\\alpha N$.\n",
    "- Compare this to the actual number of discoveries at the threshold - $N_\\alpha$.\n",
    "- Choose a p-value threshold $\\alpha$ such that $\\alpha N/N_\\alpha$ is less than a desired threshold\n",
    "  (e.g. 0.05) - this threshold would give an expected FDR of 0.05.\n",
    "- Note that the FDR is truly a property of a *set* - in a set of genes with FDR = 0.05, we can expect\n",
    "  around 5% to be false discoveries. However, we don't know *which* ones! It could be the most significant!\n",
    "- Often, we want a gene-wise measure of significance (like the p-value).\n",
    "- The q-value, or adjusted p-value, of a variable is the *smallest* FDR we have to accept in order to\n",
    "  call that variable significant.\n",
    "- For example, if the adjusted p-value is 0.2, we have to accept that if we want to call this variable\n",
    "  (and consequently, all variables with lower p-values) significant, there will be approximately 20%\n",
    "  false discoveries among them.\n",
    "\n",
    "In python :\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Bonferroni\n",
    "rejected, fwers, alphacSidak, alphacBonf = multipletests(pvals, alpha=0.05, method='bonferroni')\n",
    "\n",
    "# BH procedure\n",
    "rejected, fdrs, alphacSidak, alphacBonf = multipletests(pvals, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "# Note: many other methods are available -> help(multipletests)\n",
    "```\n",
    "\n",
    "* rejected : true for hypothesis that can be rejected for the given alpha.\n",
    "* fwers|fdrs : p-values corrected for multiple tests.\n",
    "* alphacSidak : corrected alpha for Sidak method.\n",
    "* alphacBonf : corrected alpha for Bonferroni method.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example:**\n",
    "* Imagine we perform 10'000 t-tests on 10'000 couple of random samples all taken from the exact same distribution:\n",
    "  any **significant difference in mean value among these samples** (i.e. this is what the t-test is testing)\n",
    "  **will be purely by chance** (and would lead us to wrongly reject the null hypothesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pvals = []  # A list where we will store the p-values of our t-tests.\n",
    "\n",
    "N = 10000\n",
    "mean_difference = 0 # no differences -> any detected difference is due to chance.\n",
    "sample_size = 100\n",
    "std=1\n",
    "\n",
    "for i in range(N):\n",
    "    t, pval_ttest = stats.ttest_ind(np.random.randn(sample_size) * std, \n",
    "                                    np.random.randn(sample_size) * std + mean_difference, equal_var=True)\n",
    "    pvals.append(pval_ttest)\n",
    "    \n",
    "pvals = np.array(pvals)\n",
    "# stats models proposes a function implementing numerous p-value correction methods\n",
    "# https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "rejected, fwers, alphacSidak, alphacBonf = multipletests(pvals, alpha=0.05, method=\"bonferroni\")\n",
    "rejected, fdrs, alphacSidak, alphacBonf = multipletests(pvals, alpha=0.05, method=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.histplot(pvals, bins = np.arange(0, 1.05, 0.01), ax=ax[0], label=\"p-value\", color=\"xkcd:vomit\")\n",
    "sns.histplot(fwers, bins = np.arange(0, 1.05, 0.01), ax=ax[0], label=\"FWER\", color=\"xkcd:tomato\")\n",
    "sns.histplot(fdrs, bins = np.arange(0, 1.05, 0.01), ax=ax[0], label=\"FDR\", color=\"xkcd:lavender\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(pvals, fwers, label=\"FWER\", c=\"xkcd:tomato\", alpha=0.5)\n",
    "ax[1].scatter(pvals, fdrs, label=\"FDR\", c=\"xkcd:lavender\", alpha=0.5)\n",
    "ax[1].set_xlabel(\"p-value\")\n",
    "ax[1].set_ylabel(\"corrected value\")\n",
    "\n",
    "print(\"Fraction of (spuriously) significant tests:\")\n",
    "print(\"p-value:\", sum(pvals<0.05)/N )\n",
    "print(\"FWER   :\", sum(fwers<0.05)/N )\n",
    "print(\"FDR    :\", sum(fdrs <0.05)/N )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, imagine a different scenario where 100 out of the 10'000 tests should indeed show a significant difference (because the underlying distributions from where the random numbers are drawn are different). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pvals = []\n",
    "\n",
    "N = 10000 - 100\n",
    "mean_difference = 0  # no differences -> any detected difference is due to chance.\n",
    "sample_size = 100\n",
    "std = 1\n",
    "\n",
    "for i in range(N):\n",
    "    t, pval_ttest = stats.ttest_ind(np.random.randn( sample_size ) * std, \n",
    "                                    np.random.randn( sample_size ) * std + mean_difference, equal_var=True)\n",
    "    pvals.append(pval_ttest)\n",
    "\n",
    "# Now we add the different ones:\n",
    "mean_difference = 0.75\n",
    "for i in range(100):\n",
    "    t, pval_ttest = stats.ttest_ind(np.random.randn( sample_size ) * std, \n",
    "                                    np.random.randn( sample_size ) * std + mean_difference, equal_var=True)\n",
    "    pvals.append(pval_ttest)\n",
    "    \n",
    "    \n",
    "pvals = np.array(pvals)\n",
    "# stats models proposes a function implementing numerous p-value correction methods\n",
    "# https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "rejected, fwers, alphacSidak, alphacBonf = multipletests(pvals, alpha=0.05, method=\"bonferroni\")\n",
    "rejected, fdrs, alphacSidak, alphacBonf = multipletests(pvals, alpha=0.05, method=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame({\"PV\": pvals, \"D\": N*[1] + 100 * [0]})\n",
    "sns.histplot(\n",
    "    data=_df, x=\"PV\",\n",
    "    hue=\"D\", palette=\"pastel\",\n",
    "    multiple=\"stack\", binwidth=0.025,\n",
    "    legend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of significant tests:')\n",
    "print('p-value:', sum(pvals<0.05))\n",
    "print('FWER   :', sum(fwers<0.05))\n",
    "print('FDR    :', sum(fdrs <0.05))\n",
    "print()\n",
    "print('Number of correctly significant tests (out of 100):')\n",
    "print('p-value:', sum(pvals[-100:]<0.05) )\n",
    "print('FWER   :', sum(fwers[-100:]<0.05) )\n",
    "print('FDR    :', sum(fdrs[-100:] <0.05) )\n",
    "print()\n",
    "print('Number of spuriously significant tests (out of 9900):')\n",
    "print('p-value:', sum(pvals[:-100]<0.05) )\n",
    "print('FWER   :', sum(fwers[:-100]<0.05) )\n",
    "print('FDR    :', sum(fdrs[:-100] <0.05) )\n",
    "\n",
    "print(\"Observed False Discovery Rate:\")\n",
    "print('p-value: {:.3f}'.format(sum(pvals[:-100]<0.05)/sum(pvals<0.05)))\n",
    "print('FWER   : {:.3f}'.format(sum(fwers[:-100]<0.05)/sum(fwers<0.05)))\n",
    "print('FDR    : {:.3f}'.format(sum(fdrs[:-100] <0.05)/sum(fdrs<0.05)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## 1.5 Fisher's exact test and the Chi-square test <a id='stats.5'></a>\n",
    "\n",
    "* These two tests have for object the association between 2 categorical variables.\n",
    "* Their **null hypothesis** is the absence of association between the two variable.\n",
    "\n",
    "**Fisher's exact test**, as its name entails, computes a p-value which is exact, even for very low sample sizes. However it becomes computationally complex to compute as the data set size increases or number of categories gets higher.\n",
    "\n",
    "The **Chi-square test**, in contrast, uses an approximation of the exact p-value which is only valid when samples are big enough. However, it scales well to larger samples sizes and number of categories.\n",
    "\n",
    "\n",
    "Both tests start from a **contingency table**.\n",
    "\n",
    "Here we are going to use as example the historical [Lady tasting tea](https://en.wikipedia.org/wiki/Lady_tasting_tea).\n",
    "\n",
    "|  | detected as milk before | detected as milk after | marginal sums |\n",
    "|---|---|---|---|\n",
    "| **milk before** | 3 | 1 | **4** |\n",
    "| **milk after** | 1 | 3 | **4** |\n",
    "| **marginal sums**  | **4** | **4** | **8** |\n",
    "\n",
    "In our experiment, the lady was able to correctly identify 6 out of 8 cups.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table with the results from the tea tasting.\n",
    "table = [[3,1], [1,3]]\n",
    "\n",
    "# Fisher's exact test.\n",
    "oddsratio, pvalue = stats.fisher_exact(table)\n",
    "print(\"Fisher's exact test\")\n",
    "print(\"\\todds ratio:\", oddsratio)\n",
    "print(\"\\tp-value:\", pvalue)\n",
    "\n",
    "# Chi-square.\n",
    "chi2, pval, df, expected = stats.chi2_contingency(table, correction=False)\n",
    "print(\"Chi-square test\")\n",
    "print(\"\\tchi2:\", chi2)\n",
    "print(\"\\tp-value:\", pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the p-values between Fisher's and the Chi-square tests are quite different.\n",
    "\n",
    "> Note that here we use `correction=False` as by default scipy implementation uses [Yates's correction](https://en.wikipedia.org/wiki/Yates%27s_correction_for_continuity), which is useful when the numbers are low. Try the same lines with the correction to see the difference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine now that we have many cups and a very patient lady so that the contingency table looks like this:\n",
    "\n",
    "|  | detected as milk before | detected as milk after | marginal sums |\n",
    "|---|---|---|---|\n",
    "| **milk before** | 30 | 10 | **40** |\n",
    "| **milk after** | 18 | 22 | **40** |\n",
    "| **marginal sums**  | **48** | **32** | **80** |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [[30,10], [18,22]]\n",
    "\n",
    "oddsratio , pvalue = stats.fisher_exact(table)\n",
    "print(\"Fisher's exact test\")\n",
    "print('\\todds ratio:', oddsratio)\n",
    "print('\\tp-value:', pvalue)\n",
    "\n",
    "chi2,pval , df, expected = stats.chi2_contingency(table, correction=False)\n",
    "print(\"Chi-square test\")\n",
    "print('\\tchi2:', chi2)\n",
    "print('\\tp-value:', pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see, with a larger dataset, the p-value of the Chi-square test is closer to that of Fisher's exact test (because the approximation made by the Chi-square tests is better with larger datasets).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "## Exercise 3.1\n",
    "\n",
    "Exercises are located in the dedicated notebook `exercises_course1.ipynb`.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## 1.6 1-way anova <a id='stats.6'></a>\n",
    "\n",
    "The **ANOVA**, or **AN**alyse **O**f **VA**riance, stands maybe among the most used (and abused) type of statistical tests to date.\n",
    "\n",
    "The anova is used to analyze the differences among group means in a sample. \n",
    "In particular, we are going to concentrate here on the 1-way ANOVA, which evaluates the difference in means of a numerical variable across groups formed by another (single) variable.\n",
    "\n",
    "In this sense, it is a generalization of the t-test which is limited to 2 groups only (in fact, the 1-way anova and t-test are quivalent when there are only 2 groups).\n",
    "\n",
    "**Anova assumptions**:\n",
    "* Subpopulation distributions are normal.\n",
    "* Samples have equal variances.\n",
    "* Observations are independent from one another.\n",
    "\n",
    "**Test hypothesis**: \n",
    "Given $m$ groups of mean $\\bar{x}_{1...m}$, each containing $n_i$ observations (for a total of $n$):\n",
    " * **Null hypothesis**: $H_0 : \\bar{x}_1 = \\bar{x}_2 = ... = \\bar{x}_m$\n",
    " * **Alternative hypothesis**: at least one of these means differ from the others.\n",
    " \n",
    "The anova relies on the idea that if the mean varies between the different group then the overall variance of all samples should be significantly greater than the variance within each group (hence the name).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example:**\n",
    "* In the 1880 Swiss census data: is there difference in the proportion of the number of 60+ years old depending on the main language? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here playing with the whole dataset is a bit silly, because we have the whole population.\n",
    "# So let's imagine we only went and counted this fraction in 20 communes per language.\n",
    "\n",
    "dfFractions = pd.read_csv(\"data/census1880_fractions.csv\")\n",
    "dfFractionsSample = dfFractions.groupby(\"majority language\", group_keys=False).apply(lambda x: x.sample(20))\n",
    "dfFractionsSample[\"majority language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14,7), sharey=True)\n",
    "sns.kdeplot(data=dfFractionsSample, y=\"60+ y.o.\", ax=axes[0])\n",
    "sns.rugplot(data=dfFractionsSample, y=\"60+ y.o.\", ax=axes[0])\n",
    "\n",
    "sns.violinplot(data=dfFractionsSample, x=\"majority language\", y=\"60+ y.o.\" , ax=axes[1])\n",
    "_ = axes[1].set_xticks(range(4))\n",
    "_ = axes[1].set_xticklabels( map(lambda x:x.partition(\" \")[0] , dfFractionsSample[\"majority language\"].unique()) , \n",
    "                            rotation = 20, rotation_mode='anchor',ha='right')\n",
    "# The last line removes the \"speaker\" at the end of x-axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice trick to aggregate this data as a set of lists.\n",
    "aggregated60fraction = dfFractionsSample.groupby('majority language')['60+ y.o.'].agg(list)\n",
    "aggregated60fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fstat, pval = stats.f_oneway(*aggregated60fraction)\n",
    "# equivalent to stats.f_oneway( aggregated60fraction[0] , aggregated60fraction[1] , ... )\n",
    "\n",
    "print(\"automated 1-way anova / F-test:\")\n",
    "print(\"F-stat :\",Fstat)\n",
    "print(\"p-value:\",pval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this, it can be nice to report the mean and standard deviation of each group.\n",
    "dfFractionsSample.groupby('majority language')['60+ y.o.'].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the ANOVA only tests if there is at least one significant difference between groups.\n",
    "\n",
    "If you want to test for each differences, then **after an ANOVA**, we recommend [Tukey's honestly significant difference](https://docs.scipy.org/doc/scipy-1.8.1/reference/generated/scipy.stats.tukey_hsd.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.tukey_hsd(*aggregated60fraction)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The categories Ids correspond to the order in which the lists were provided:\n",
    "for i, n in enumerate(aggregated60fraction.index):\n",
    "    print(i,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can visualize the results as a p-value heatmap.\n",
    "sns.heatmap( np.log10( res.pvalue ), \n",
    "            xticklabels = aggregated60fraction.index , \n",
    "            yticklabels = aggregated60fraction.index  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Of course, there exists many other tests implemented in `scipy.stats` (as well as other libraries). Here is a little [cheat-sheet](https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/) to help you explore this. \n",
    "\n",
    "> Scipy.stats documentation is also great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# 2. Correlation and linear regression <a id='reg'></a>\n",
    "-----------------------------------------------\n",
    "\n",
    "## 2.1 Correlation <a id='reg.1'></a>\n",
    "\n",
    "**Correlation** is a measure of the amount of relatedness between two measured variables. It comes in several flavours :\n",
    " * **Pearson's linear correlation** coefficient: for linear relationship only: **`stats.pearsonr(x,y)`**\n",
    " * **Spearman's rank correlation** coefficient: accepts non linear, but \"monotonic only\":\n",
    "   **`stats.spearmanr(x,y)`**\n",
    " * **Kendall's Tau**: relies on value order relation only, and is less influenced by the scale than\n",
    "   the two others: **`stats.kendalltau(x,y)`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=1./5\n",
    "\n",
    "linear=[[u,(u)/100+sigma*np.random.randn()] for u in range(10,500)]\n",
    "monotonic=[[u,50*(0.8**(u/10))+sigma*np.random.randn()] for u in range(10,500)]\n",
    "\n",
    "non_monotonic=[[u,(u)**3+3*u**2+sigma*np.random.randn()] for u in np.arange(-1,1,1./250)]\n",
    "\n",
    "together=[linear,monotonic,non_monotonic]\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "for i in range(3):\n",
    "    x=[u[0] for u in together[i]]\n",
    "    y=[u[1] for u in together[i]]\n",
    "    ax[i].scatter(x,y)\n",
    "    ax[i].set_title('Pearson   : {0:.3f}, \\nSpearman: {1:.3f}, \\nKendall   : {2:.3f}'.format(\n",
    "                                    stats.pearsonr(x,y)[0],##just like that\n",
    "                                    stats.spearmanr(x,y)[0],\n",
    "                                    stats.kendalltau(x,y)[0]))\n",
    "fig.tight_layout()    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to toc](#toc)\n",
    "\n",
    "<br>\n",
    "\n",
    "## 2.2 Regression <a id='reg.2'></a>\n",
    "\n",
    "Performing regression (linear or otherwise) is possible with `scipy`, but it is not the best module for this task.\n",
    "\n",
    "`statsmodels` offers much nicer options and statistical reports. \n",
    "\n",
    "<!--\n",
    "Additionally, this is a great opportunity to see together how to install a library. \n",
    "\n",
    "1. Go to [https://www.statsmodels.org](https://www.statsmodels.org).\n",
    "2. Click on the install page.\n",
    "3. Find the instruction for installation with Anaconda.\n",
    "4. Type the command in either a terminal (mac, linux) or in the anaconda-prompt (windows).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Let's load our data using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes = pd.read_table(\"data/diabetes.csv\", sep=\",\")\n",
    "\n",
    "# Rename columns to replace spaces by underscore\n",
    "df_diabetes.rename( columns = lambda x : x.replace(\" \",\"_\") , inplace=True)\n",
    "df_diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_diabetes[\"bmi\"]                  # Covariable bmi.\n",
    "y = df_diabetes[\"disease_progression\"]  # Response variable disease progression.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))  # Setup graphical windows.\n",
    "sns.scatterplot(x=x, y=y)                 # Plot x versus y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(df_diabetes[\"bmi\"], df_diabetes[\"disease_progression\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using the statsmodel package, which computes a lot of cool metrics for you.\n",
    "import statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols(\"disease_progression ~ bmi\" , data=df_diabetes)\n",
    "\n",
    "## Alternative syntax: \n",
    "# import statsmodels.api as sm\n",
    "# X = sm.add_constant(x) # Adding a intercept to the model.\n",
    "# model = sm.OLS(y, X)   # Defining an Ordinary Least Square variable.\n",
    "\n",
    "results = model.fit()  # Fitting the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plots:\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = (15, 6))\n",
    "\n",
    "# Plotting residuals (error of the model) vs. fitted values (prediction fo the model)\n",
    "# helps determine homosedascticity and sphericity of errors:\n",
    "# the points should show about the same spread all along the x axis, and be centered around 0.\n",
    "axes[0].scatter( results.fittedvalues , results.resid )\n",
    "axes[0].axhline(0.0, color=\"grey\")\n",
    "axes[0].set_xlabel(\"fitted values\")\n",
    "axes[0].set_ylabel(\"residuals\")\n",
    "\n",
    "# The QQplot (quantile-quantile plot) is  great plot to assess normality of the\n",
    "# model's residuals. Basically points should stay close to the diagonal line if\n",
    "# they follow something close to a normal distribution.\n",
    "qqplot(results.resid, ax=axes[1], line=\"s\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the fit.\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "# We obtain the predicted values for our model, as well as their 95% intervals.\n",
    "prstd, iv_l, iv_u = wls_prediction_std(results) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "#ax.plot(x, y, 'o', label=\"data\")\n",
    "sns.scatterplot(x=x,y=y) # plot x versus y\n",
    "ax.plot(x, results.fittedvalues, \"r\", label=\"OLS regression result\")\n",
    "ax.plot(x, iv_u, color=\"orange\",linestyle=\"--\" , label=\"95% fit interval\")\n",
    "ax.plot(x, iv_l, color=\"orange\",linestyle=\"--\")\n",
    "ax.legend(loc=\"best\", fontsize=10)\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple ordinary least square linear regression with a single covariable, \n",
    "but stats models is able to handle much more complex models such as [GLMs](https://www.statsmodels.org/stable/glm.html) , [time series analysis](https://www.statsmodels.org/stable/tsa.html), [survival analysis](https://www.statsmodels.org/stable/duration.html), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "## Exercise 3.2 - Free-form exercise\n",
    "\n",
    "Exercises are located in the dedicated notebook `exercises_course1.ipynb`.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
